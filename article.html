<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AI Safety — Insight Cyber</title>
  <meta name="description" content="Practical AI safety basics">
  <link rel="stylesheet" href="assets/styles.css">
  <script type="application/ld+json">
  {
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "AI Safety",
  "datePublished": "2025-09-15T03:14:16Z",
  "dateModified": "2025-09-15T03:14:16Z",
  "author": {
    "@type": "Person",
    "name": "Malvika Mishra"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yourusername.github.io/article.html"
  }
}
  </script>
</head>
<body>
  <a class="skip-link" href="#content">Skip to content</a>
  <header class="site-header">
    <div class="container nav">
      <a class="brand" href="./">
        <span class="logo" aria-hidden="true"></span>
        <span class="title">Insight Cyber</span>
        <small>Blog</small>
      </a>
      <nav aria-label="Primary">
        <a href="index.html">Home</a>
        <a href="about.html">About</a>
      </nav>
    </div>
  </header>

  <main id="content" class="container article">
    <nav class="breadcrumbs" aria-label="Breadcrumbs">
      <a href="index.html">Home</a> › <span>Articles</span> › <span aria-current="page">AI Safety</span>
    </nav>

    <article class="card prose" style="padding:2rem;">
      <header>
        <p class="kicker">AI Safety</p>
        <h1>AI Safety</h1>
        <p class="byline">By Malvika Mishra · Published 2025-09-15 · 15 min. read</p>
      </header>

      <p>Artificial Intelligence is a rapidly advancing field that can be applied to nearly any line of work to increase productivity. A plethora of AI tools are available on the market that do not require any technical or field knowledge to be used. As the use of AI becomes more common, it is essential for both individuals and organizations to stay safe while using AI. </p>
      
      <p>Here are some simple steps that you can take while using AI to ensure your organization’s and your safety:</p>

      <h2>Organizational Safety</h2>
      
      <p>Organizations often use AI to automate workflows for efficiency, to process and analyze large quantities of data, and to enhance decision-making. Sometimes employees use AI to help with their tasks without the explicit permission from the organization. As organizations deal with customer data, they need to ensure its safety and privacy, which means ensuring that all AI use within the organization is permitted and safe. Organizations can use the following for AI safety:</p>

      <p><Strong>AI Governance Policies & Procedures:</Strong> Make sure clear policies and procedures are in place to avoid AI misuse and unauthorized use of AI, known as shadow AI. These policies should include the approved AI tools, acceptable usage of tools, etc.</p>
      <p><Strong>Run Local LLMs:</Strong> Running Large Language Models on the user’s personal device, like laptops, or on a host on your trusted network, provides more privacy as your data is not processed on a third-party cloud and reduces the reliance on vendors.</p>
      <p><Strong>Vet AI tools before use:</Strong> Before using a third-party tool, ensure that it will not introduce unnecessary risks to your system. This <a href="https://futureoflife.org/ai-safety-index-summer-2025/">AI safety index</a> compares the safety of some of the more popular AI tools, or compare them yourself using criteria like:</p>
      <ul class="list-check">
          <li>Ongoing legal issues and copyright claims</li>
          <li>Output accuracy and biases</li>
          <li>Terms of service and privacy policy*</li>
          <li>Transparency of training data used</li> </ul>
      <p class="muted"><em>*Legal mandates will take precedence over the organization’s privacy policy, like in the case of   OpenAI, which provides an option for deleting chats but is legally bound not to delete chat histories.</em></p>
      <p><Strong>Data Anonymization for Privacy:</Strong>  Ensure data anonymization, i.e., remove any Personal Identifiable Information from the data used in model training and prompts, to ensure that the organization’s and its customers’ privacy is protected.</p>
      <p><Strong>User awareness and training:</Strong> Make sure users using the AI are aware of the risks posed by it and train them on safe AI use.</p>
      <p><Strong>Maintain a good cybersecurity posture:</Strong>A good overall cybersecurity posture will help mitigate any added risks from attackers that can exploit AI vulnerabilities. Use frameworks like the <a href="https://www.nist.gov/itl/ai-risk-management-framework">NIST’s AI Risk Management Framework</a> to ensure security for AI.</p>
      <p><Strong>Least Privilege:</Strong> The AI tools and the users should only have access to the minimum data and system capabilities necessary for their function to reduce the risk of data leakage and misuse</p>
      <p><Strong>Compliance:</Strong> Ensure that your organization’s AI use is compliant with all applicable laws and regulations, including the GDPR, EU AI Act, US Civil Rights Act, etc.</p>
      <p><Strong>Human Oversight:</Strong> Most AIs are prone to hallucinations and biases. Trained personnel are essential for verifying AI-generated information and making critical decisions.</p>
      <p><Strong>Monitor AI Usage:</Strong> Implement continuous monitoring of AI usage to ensure that procedures are being followed and to reduce the risk of shadow AI.</p>
      <p><Strong>Transparency about AI use:</Strong> To maintain the client’s trust, be transparent about AI use in your organization.</p>

      <h2>Personal Safety</h2>
      <p>People use AI tools in their personal lives to increase convenience and productivity. Since individuals do not have to worry about customer data or compliance, they do not have to follow the stringent requirements for safety that organizations follow. This, however, does not mean that individuals do not have to practice safety while using AI, as their and their family’s personal information needs to be protected from being collected and to reduce the chance of identity theft due to data leakage. The steps below can help protect an individual while using AI tools:</p>

          <p><Strong>Choose reputable AI tools:</Strong> Not all AI tools are created equal. Some tools have robust security, while others can be more susceptible to biases and attacks. Use the <a href="https://futureoflife.org/ai-safety-index-summer-2025/">AI safety index</a> and choose a safe tool to ensure data safety.</p>
          <p><Strong>Privacy settings:</Strong> Before using a tool, understand its privacy policies to know how your data will be stored and used.</p>
          <p><Strong>Be careful with what you share:</Strong> Do not share personal information like name, phone number, social security number, or other identifiable information, as AI tools can store it. This data can become a part of the AI's training data, which can lead to accidental exposure by the AI tools.</p>
          <p><Strong>Limit Permissions:</Strong> Turn off the content sharing option for model training to make sure your data does not leak through AI outputs. Also, turn off chat referencing options to make sure that your data is not used outside the chat.</p>
          <p><Strong>Avoid using the free versions of AI tools:</Strong> Free versions of AI tools give less or no privacy control to the user. Instead of using free versions of many different tools, use paid versions of the tools you actually need.</p>
          <p><Strong>Double-check the output:</Strong> Generative AIs are prone to giving incorrect or nonsensical outputs, known as hallucinations. Double-check any output given by an AI tool to make sure that it’s accurate.</p>
          <p><Strong>Make sure the content is plagiarism-free:</Strong> Generative AIs can reproduce their training data with minimal changes. As most AIs are trained on data from all over the internet, AIs reproducing data that may be copyrighted is a high possibility. To ensure there is no plagiarism, use the AI response as a first draft, or ask the AI tool to list all the sources used, and compare the output with the source.</p>
          <p><Strong>Stay Informed:</Strong> With AI technology progressing rapidly, its malicious uses, like deepfake generation, are also getting highly sophisticated. It is important to stay on top of AI-related news to know how to identify malicious AI usage.</p>
          <p><Strong>Good Cybersecurity:</Strong> Practice good cybersecurity hygiene, like using strong passwords and Multi-Factor Authentication, to make sure you and your data are safe on the internet.</p>
          <hr>
      <p class="muted">Enjoyed this? <a href="about.html">Say hi</a> or check the homepage.</p>
    </article>
  </main>

  <footer class="site-footer">
    <div class="container">
      <div>© 2025 Insight Cyber</div>
    </div>
  </footer>
</body>
</html>
